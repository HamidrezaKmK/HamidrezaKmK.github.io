<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Hamid Kamkari</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="academia.html">Academia</a></div>
<div class="menu-item"><a href="industry.html">Industry</a></div>
<div class="menu-item"><a href="competitive-programming.html">Competitive&nbsp;Programming</a></div>
<div class="menu-item"><a href="projects.html">Projects</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Hamid Kamkari</h1>
</div>
<table class="imgtable"><tr><td>
<img src="./images/profile.jpg" alt="Hamidreza Kamkari" width="170px" height="220px" />&nbsp;</td>
<td align="left"><p>Machine Learning Research Intern at<br />
<a href="https://layer6.ai/" target=&ldquo;blank&rdquo;>Layer6 AI</a>
</p>
<p>Master of Science at<br />
<a href="https://mscac.utoronto.ca/" target=&ldquo;blank&rdquo;>University of Toronto</a>
</p>
<p>Bachelor of Science at<br />
<a href="http://www.en.sharif.edu/" target=&ldquo;blank&rdquo;>Sharif University of Technology</a>
</p>
<p>Contact: hamidrezakamkari (at) gmail (dot) com
</p>
</td></tr></table>
<h2>About Me</h2>
<p>An M.Sc. student delving into the nexus of machine learning fundamentals, focusing on AI reliability, explainability, and their ties to statistical foundations.
</p>
<p>Currently, I am interning at <a href="https://layer6.ai/" target=&ldquo;blank&rdquo;><b>Layer6 AI</b></a> as a Machine Learning Scientist, delving deep into the reliability of generative models.
Specifically, I am looking at pathological behaviours that modern generative models exhibit when they are employed on Out-of-Distribution data that they
have not seen before. Additionally, explaining such behaviours using a <b>Manifold Learning Theory</b> perspective fascinates me.
</p>
<p>As a competitive programmer with a zest for both the theoretical and practical aspects of computer science, I am always vigilant about integrating the best engineering practices in my work.
My industry tenure as a Machine Learning Engineer has enriched my perspective, marrying theory with real-world applicability. 
The engineering aspects of machine learning research are challenging as they involve continuous development of a codebase that might change drastically due to the inherent nature of research. 
Therefore, in my free time, I enjoy thinking about and implementing new libraries that help research scientists in their research journey as well as seamlessly blending abstract concepts with real-world applications.
</p>
<h2>Highlights</h2>
<ul>
  <li>
  <p style="text-align:left;">
  <strong> Explaining a Popular Paradox in Deep Generative Models </strong> - <em> <a href="https://layer6.ai/">Layer6 AI</a> - Toronto, Canada </em>
    <span style="float:right;"> 
        <em> September 2023 </em>
    </span>
  </p>
  </li>
  <p>
  We examine the paradox of deep generative models assigning high likelihoods to unseen data and propose a method to improve their reliability and theoretical understanding in out-of-distribution detection.
  
  <li>
  <p style="text-align:left;">
  <strong> Causal Discovery and Inference using Normalizing Flows</strong> - <em> <a href="https://vectorinstitute.ai/">Vector Institute</a> - Toronto, Canada </em>
    <span style="float:right;"> 
        <em> May 2023 </em>
    </span>
  </p>
  </li>
  <p>
  Introduced a novel neural network architecture that can learn to understand the underlying structure of the data-generating process. This ultimately
  helps us produce reliable and explainable models that can account for interventional distributions unseen in the training data. [<a href="https://github.com/vahidzee/ocdaf">Code</a>] [<a href="https://arxiv.org/abs/2308.07480">Paper</a>] 

<li>
  <p style="text-align:left;">
  <strong> Dysweep </strong> - <em> <a href="https://vectorinstitute.ai/">Vector Institute</a> - Toronto, Canada </em>
    <span style="float:right;"> 
        <em> January 2023 </em>
    </span>
  </p>
  </li>
  <p>
  An integration with <a href="https://wandb.ai/">Weights & Biases</a> that provides a pipeline to aid reproducibility, continuous development, and large-scale benchmarking. [<a href="https://github.com/HamidrezaKmK/dysweep">Code</a>]

 <li> 
  <p style="text-align:left;">
  <strong> Attention-based Drug Discovery </strong> - <em> <a href="https://ce.sharif.edu/">Sharif University</a> - Tehran, Iran </em>
    <span style="float:right;"> 
        <em> June 2022 </em>
    </span>
  </p>
  </li>
  <p>
  Thesis leveraged attention mechanisms in deep learning to identify synergistic drug combinations for cancer research. 
  Achieved a 1.5x accuracy boost in dose response prediction for the NCI-ALMANAC cancer drug database.
<li>
  <p style="text-align:left;">
  <strong> RNA Sequence design using Graph Neural Networks </strong> - <em> <a href="https://www.aalto.fi/en">Aalto University</a> - Espoo, Finland </em>
    <span style="float:right;"> 
        <em> September 2021 </em>
    </span>
  </p>
  </li>
  <p>
  Designing beneficial RNA structures is challenging in biotechnology. 
  We use reinforcement learning algorithms combined with graph neural networks to model and design RNA sequences, 
  obtaining previously underexplored structures like RNA pseudo-knots.
  <li>
  <p style="text-align:left;">
  <strong> Semi-definite Programming using Slime Molds </strong> - <em> <a href="https://www.mpi-inf.mpg.de/home">Max-Planck for Informatics</a> - Saarbr√ºcken, Germany </em>
    <span style="float:right;"> 
        <em> June 2021 </em>
    </span>
  </p>
  </li>
  <p>
  Inspired by the optimization dynamics of slime molds in nature, 
  developed a mathematical dynamic that provably converges to the optimal solution for semi-definite programming problems.
  [<a href="https://arxiv.org/abs/2111.02291">Paper</a>]

</ul>
</td>
</tr>
</table>
</body>
</html>
