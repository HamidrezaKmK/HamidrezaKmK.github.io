<div style='padding-left: 20px; padding-right: 20px; padding-top: 10px; padding-bottom: 10px;'><img src="/project5.png"
        alt="Fine-Grained Complexity of Optimizing Bias Terms in Neural Networks"><br />
    <p>The study of the complexity of learning neural networks is of high importance in the infinite quest of shedding
        light upon some theoretical aspects of them. One particular problem of interest is the problem of fine-tuning
        such networks. To explore the problem, we limit ourselves to a subset of weights and try to fix the other
        weights while optimizing this set according to the input data. In this work, we have addressed the complexity of
        fine-tuning bias terms in a fine-grained fashion and proved that even for a simple one-hidden layer neural
        network we require a lot of processing time to optimize these weights deterministically.</p>
    <p style='color: #ff0000;'>Andreas Karrenbauer, Hamidreza Kamkari, Karl Bringmann</p>
</div>