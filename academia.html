<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Academia</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="academia.html" class="current">Academia</a></div>
<div class="menu-item"><a href="industry.html">Industry</a></div>
<div class="menu-item"><a href="competitive-programming.html">Competitive&nbsp;Programming</a></div>
<div class="menu-item"><a href="projects.html">Projects</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Academia</h1>
</div>
<h2>Education</h2>
<ul>
  <li>
  <p style="text-align:left;">
  Master of Science in Applied Computing <em> - <strong> <a href="https://mscac.utoronto.ca/"> University of Toronto </a> </strong> , Canada </em>
    <span style="float:right;"> 
        <em> September 2022 - December 2024 </em>
    </span>
  </p>
  </li>
  <p>
  <strong> Courses include </strong>: (CSC2541) Topics in Machine Learning, Introduction to Causality (A+), (CSC2240) Graphs, Matrices, and Continuous Optimization, (CSC2701) Communication for Computer Scientists, (CSC2541) Advanced Topics in ML: Causal-aware
Representation Learning (A), (CSC2130) Empirical Research Methods in Software Engineering (A+)
  </p>

   <li>
  <p style="text-align:left;">
  Bachelors in Computer Engineering<em> - <strong> <a href="https://ce.sharif.edu/"> Sharif University </a> </strong> , Iran </em>
    <span style="float:right;"> 
        <em> (Honours student) September 2018 - June 2022 </em>
    </span>
  </p>
  </li>
  <p>
  <strong> Courses include </strong>: (CE695) Stochastic Processes, (CE417) Artificial Intelligence, (CE494) Introduction to Computational Biology, (CE282)
Linear Algebra, (CE181) Fundamentals of Probability and Statistics, (CE354) Algorithm Design, (CE415) Theory of Formal Languages and Automata, (MAT034) Differential Equations
  </p>
  
</ul>
<h2>Publications</h2>
<ul>
<li>
  <div style="text-align:left;">
   Explaining the Out-of-Distribution Detection Paradox through Likelihood Peaks
    <span style="float:right;"> 
        <em> September 2023 </em>
    </span>
  </div>
  <div style="text-align:left; padding-top: 5px;"> 
    <em> <a href="https://layer6.ai/"> Layer6 AI </a>, <a href="https://web.cs.toronto.edu/"> University of Toronto </a> - Toronto, Canada - (Under Review in ICLR) </em>
  </div>
  </li>
  <br>
  <p>
 Likelihood-based deep generative models (DGMs) commonly exhibit a puzzling behaviour: 
when trained on a relatively complex dataset, they assign higher likelihood values to out-of-distribution (OOD) data from simpler sources. 
Adding to the mystery, OOD samples are never generated by these DGMs despite having high likelihoods. 
This two-pronged paradox has yet to be conclusively explained, making likelihood-based OOD detection unreliable. 
Our primary observation is that high-likelihood regions will not be generated if they contain minimal probability mass, 
which can occur if the density is sharply peaked. We demonstrate how this seeming contradiction of large densities yet 
low probability mass can occur on data confined to low dimensional manifolds. We also show that this scenario can be identified 
through local intrinsic dimension (LID) estimation, and propose a method for OOD detection which pairs the likelihoods and LID estimates 
obtained from a pre-trained DGM. Moreover, we provide an efficient method for estimating LID from a normalizing flow model, improving upon 
existing estimators, and enabling state-of-the-art OOD detection performance with respect to comparable flow-based benchmarks.
  </p>
  
<li>
  <div style="text-align:left;">
   Ordered Causal Discovery with Autoregressive Flows <em>  </em>
    <span style="float:right;"> 
        <em> May 2023 </em>
    </span>
  </div>
  <div style="text-align:left; padding-top: 5px;"> 
    <em> <a href="https://vectorinstitute.ai/"> Vector Insitute </a>, <a href="https://web.cs.toronto.edu/"> University of Toronto </a> - Toronto, Canada - (Under Review in AISTATS) </em>
  </div>
  </li>
  <br>
  <p>
 We propose OCDaf, a novel order-based method for learning causal graphs from observational data. 
 We establish the identifiability of causal graphs within multivariate heteroscedastic noise models, 
 a generalization of additive noise models that allow for non-constant noise variances. 
 Drawing upon the structural similarities between these models and affine autoregressive normalizing flows, 
 we introduce a continuous search algorithm to find causal structures. Our experiments demonstrate state-of-the-art performance 
 across the Sachs and SynTReN benchmarks in Structural Hamming Distance (SHD) and Structural Intervention Distance (SID). 
 Furthermore, we validate our identifiability theory across various parametric and nonparametric synthetic datasets and 
 showcase superior performance compared to existing baselines.
  </p>

  <li>
  <div style="text-align:left;">
  Thesis Project on Combination Therapy - Iran
    <span style="float:right;"> 
        <em> Ongoing </em>
    </span>
  </div>
  <div style="text-align:left; padding-top: 5px;"> 
    <em> <a href="https://ce.sharif.edu/"> Sharif University </a> - Tehran - Iran </em>
  </div>
  </li>
  <br>
  <p>
  Combination therapies have emerged as a powerful treatment modality to overcome drug resistance and improve treatment efficacy. 
  However, the rapid increase of drug combinations with the number of individual drugs in consideration has led to <em>in Silico</em>
   simulations becoming widespread. While many studies are only able to find synergistic pairs of drugs, our method which is named 
   DeepDDR obtains the full dose-response matrices of different drug tuples which enables finding the optimal dose required for many applications.
    Additionally, this approach offers a more in-depth view of the drugs' complex response landscape and allows us to calculate different synergy 
    metrics as a follow-up step. From a technical perspective, DeepDDR facilitates Graph Neural Networks and multi-head attention with the goal 
    of identifying the most effective drug combinations for further pre-clinical and clinical validation. In this work, we propose a general
     recipe for devising Deep Neural Network architectures that can predict dose responses for multiple drugs on a specific cell line. 
     In our opinion, this framework can inspire future work to create new models and further address the drug-dose response problem. 
     Graph Neural Networks and Attention-based models have emerged as powerful machine learning tools in many applications; therefore, we
      incorporate popular architectures in the domain to obtain latent embeddings of drug compounds and combine cell-line features with these 
      embeddings. By analogy, while previous work on drug-dose response considers MACCS fingerprints to represent drug compounds, we follow the 
      trend of using Graph Neural Networks on SMILES notations of compounds to produce more accurate embeddings of drugs. These embeddings 
      can take into account the structure of the compound as a whole. Finally, our findings indicate that using DeepDDR yields state-of-the-art 
      results on the comprehensive drug-dose-response NCI-ALMANAC dataset which contains drug pair dose responses on popular human cancer cell lines.
  </p>
   
  
  <li>
  <div style="text-align:left;">
    Physarum Inspired Dynamics to Solve Semi-Definite Programs
    <span style="float:right;">
        <em>June 2021</em>
    </span>
  </div>
  <div style="text-align:left; padding-top: 5px;"> 
    <em> <a href="https://www.mpi-inf.mpg.de/home"> Max Planck Institute for Informatics </a> - Saarbr√ºcken - Germany - (<a href="https://arxiv.org/abs/2111.02291">Paper</a>) </em>
  </div>
  </li>
  <br>
  <p>
  Physarum Polycephalum is a slime mold that can solve shortest path problems.
  A mathematical model based on Physarum's behavior, known as the Physarum Directed Dynamics, 
  can solve positive linear programs. In this paper, we present a family of Physarum-based dynamics extending 
  the previous work and introduce a new algorithm to solve positive Semi-Definite Programs (SDP). 
  The Physarum dynamics are governed by orthogonal projections (w.r.t. time-dependent scalar products) on the 
  affine subspace defined by the linear constraints. We present a natural generalization of the scalar products used in the 
  LP case to the matrix space for SDPs, which boils down to the linear case when all matrices in the SDP are diagonal, thus, 
  representing an LP. We investigate the behavior of the induced dynamics theoretically and experimentally, 
  highlight challenges arising from the non-commutative nature of matrix products, and prove soundness and convergence under mild conditions. 
  Moreover, we consider a more abstract view on the dynamics that suggests a slight variation to guarantee unconditional soundness and
   convergence-to-optimality. By simulating these dynamics using suitable discretizations, one obtains numerical algorithms for solving positive SDPs,
    which have applications in discrete optimization, e.g., for computing the Goemans-Williamson approximation for MaxCut or the Lovasz theta 
    number for determining the clique/chromatic number in perfect graphs.
  </p>
</ul>
<h2>Paper Reviews</h2>
<ul>
  <li>
  <p style="text-align:left;">
  Official Reviewer for <a href="https://iclr.cc/"> Twelfth International Conference on Learning Representations </a>
    <span style="float:right;"> 
        <em> October 2023 </em>
    </span>
	</p>
  </li>
  

  <li>
  <p style="text-align:left;">
  Official Reviewer for <a href="https://nips.cc/"> Thirty-seventh Conference on Neural Information Processing Systems </a>
    <span style="float:right;"> 
        <em> August 2023 </em>
    </span>
	</p>
  </li>
</ul>
<h2>Teaching Assistance</h2>
<ul>
  <li>
  <p style="text-align:left;">
  (CSC384) Introduction to Artificial Intelligence <a href="https://www.cs.toronto.edu/~axgao/"> Alice Gao </a>
    <span style="float:right;"> 
        <em> January 2022 - June 2022 </em>
    </span>
	</p>
  </li>

  <li>
  <p style="text-align:left;">
  (CSC236) Introduction to the Theory of Computation <a href="https://www.cs.toronto.edu/~fpitt/"> Fran√ßois Pitt </a>
    <span style="float:right;"> 
        <em> September 2022 - December 2022 </em>
    </span>
	</p>
  </li>

  <li>
  <p style="text-align:left;">
  (CE40417) Artificial Intelligence course <a href="http://blogs.bu.edu/mhrohban/"> Mohammad Hossein Rohban </a>
    <span style="float:right;"> 
        <em> September 2021 - January 2022 </em>
    </span>
	</p>
  </li>
  
  <li>
  <p style="text-align:left;">
  (CE40254) <bf> Head </bf> of Data Structure and Algorithms course <a href="http://sharif.edu/~ghodsi/"> Mohammad Ghodsi </a>
    <span style="float:right;"> 
        <em> January 2021 - June 2021 </em>
    </span>
	</p>
  </li>
  
  <li>
  <p style="text-align:left;">
  (CE40417) Artificial Intelligence course <a href="http://blogs.bu.edu/mhrohban/"> Mohammad Hossein Rohban </a>
    <span style="float:right;"> 
        <em> January 2021 - June 2021 </em>
    </span>
	</p>
  </li>
  
  <li>
  <p style="text-align:left;">
  (CE40181) Probability and Statistics course <a href="https://scholar.google.com/citations?user=GbJMZLIAAAAJ&hl=en"> Ali Sharifi-Zarchi </a>
    <span style="float:right;"> 
        <em> September 2020 - January 2021 </em>
    </span>
	</p>
  </li>
  
  <li>
  <p style="text-align:left;">
  (CE40115) Discrete Structures course <a href="https://scholar.google.com/citations?user=xuNJ-d8AAAAJ&hl=en"> Mohammad Ali Abam </a>
    <span style="float:right;"> 
        <em> January 2020 - June 2020 </em>
    </span>
	</p>
  </li>
  
  <li>
  <p style="text-align:left;">
  (CE40354) Advanced Algorithm design course <a href="https://scholar.google.com/citations?user=GbJMZLIAAAAJ&hl=en"> Ali Sharifi-Zarchi </a>
    <span style="float:right;"> 
        <em> January 2020 - June 2020 </em>
    </span>
	</p>
  </li>
  
  <li>
  <p style="text-align:left;">
  (CE40254) Data structure and Algorithms course <a href="https://scholar.google.com/citations?user=TNfL9SIAAAAJ&hl=en"> Mahdi Safarnejad-Boroujeni </a> 
    <span style="float:right;"> 
        <em> January 2020 - June 2020 </em>
    </span>
	</p>
  </li>
  
  <li>
  <p style="text-align:left;">
  (CE40254) Data structure and Algorithms course <a href="https://scholar.google.com/citations?user=TNfL9SIAAAAJ&hl=en"> Mahdi Safarnejad-Boroujeni </a> 
    <span style="float:right;"> 
        <em> September 2019 - January 2020 </em>
    </span>
	</p>
  </li>
</ul>
</td>
</tr>
</table>
</body>
</html>
